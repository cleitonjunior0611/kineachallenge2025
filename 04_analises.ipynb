{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8bb7f783-2615-4359-a686-4994edaf3057",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# 1. Análises Comparativas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1936fcfd-f9e3-4174-8aad-e0673dfffeba",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.1. Análises IntraClusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c8d52c-3eae-41d5-8735-2d8bb5ba1e70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from datetime import date\n",
    "\n",
    "class ClusterMetrics:\n",
    "    \"\"\"\n",
    "    Classe para análise estatística de clusters de fundos de investimento.\n",
    "    Realiza carregamento de dados, preparação de colunas auxiliares e cálculo de métricas agregadas,\n",
    "    incluindo médias, desvios padrão, proporções e índice de concentração HHI.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spark, tipo_fundo: str):\n",
    "        \"\"\"\n",
    "        Inicializa a classe com o objeto Spark e o tipo de fundo.\n",
    "        :param spark: sessão Spark ativa\n",
    "        :param tipo_fundo: tipo de fundo a ser analisado (ex: 'fidc', 'fii', 'fip')\n",
    "        \"\"\"\n",
    "        self.spark = spark\n",
    "        self.tipo_fundo = tipo_fundo.lower()\n",
    "        self.df = None\n",
    "        self.final_df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Carrega os dados do cluster para o tipo de fundo especificado.\n",
    "        Espera-se que a tabela contenha as colunas necessárias para as análises seguintes.\n",
    "        \"\"\"\n",
    "        path = f\"desafio_kinea.prospecto_fundos.resultados_cluster_{self.tipo_fundo}\"\n",
    "        self.df = self.spark.table(path)\n",
    "\n",
    "    def prepare_columns(self):\n",
    "        \"\"\"\n",
    "        Prepara colunas auxiliares para análise, como idade do fundo e flag de chamada de capital IPCA.\n",
    "        'idade_anos' é calculada como a diferença entre a data atual e a menor data de emissão por CNPJ.\n",
    "        Cria flag binária para identificar fundos com chamada de capital IPCA.\n",
    "        \"\"\"\n",
    "        w_cnpj = Window.partitionBy(\"cnpj\")\n",
    "        self.df = self.df.withColumn(\n",
    "            \"idade_anos\",\n",
    "            F.datediff(F.current_date(), F.min(\"data_emissao\").over(w_cnpj)) / 365.25\n",
    "        )\n",
    "        self.df = self.df.withColumn(\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            F.when(\n",
    "                F.upper(F.coalesce(F.col(\"chamada_capital_ipca\"), F.lit(\"NÃO\"))).like(\"%SIM%\"),\n",
    "                1\n",
    "            ).otherwise(0)\n",
    "        )\n",
    "\n",
    "    def calculate_aggregates(self):\n",
    "        \"\"\"\n",
    "        Calcula métricas agregadas por cluster, incluindo médias, desvios padrão e índice HHI.\n",
    "        volume_total_global é o somatório do volume_base_emissao de todos os fundos do tipo analisado.\n",
    "        Agrega métricas estatísticas por cluster_id_full e calcula o índice de concentração HHI\n",
    "        para o volume_base_emissao dentro de cada cluster_id_full.\n",
    "        Junta as métricas agregadas com o HHI e calcula a participação de mercado do cluster.\n",
    "        \"\"\"\n",
    "        volume_total_global = self.df.agg(F.sum(\"volume_base_emissao\").alias(\"total\")).collect()[0][\"total\"]\n",
    "\n",
    "        agg_df = self.df.groupBy(\"cluster_id_full\").agg(\n",
    "            F.countDistinct(\"cnpj\").alias(\"qtd_fundos\"),\n",
    "            F.round(F.mean(\"volume_base_emissao\"), 2).alias(\"media_volume_base_emissao\"),\n",
    "            F.round(F.mean(\"qt_emissoes\"), 2).alias(\"media_qt_emissoes\"),\n",
    "            F.mean(\"valor_cota_emissao\").alias(\"media_valor_cota_emissao\"),\n",
    "            F.mean(\"taxa_distribuicao_emissao\").alias(\"media_taxa_distribuicao_emissao\"),\n",
    "            F.mean(\"quantidade_cotas_totais\").alias(\"media_quantidade_cotas_totais\"),\n",
    "            F.mean(\"percentual_oferta_institucional\").alias(\"media_percentual_oferta_institucional\"),\n",
    "            F.mean(\"montante_minimo_emissao\").alias(\"media_montante_minimo_emissao\"),\n",
    "            F.stddev(\"volume_base_emissao\").alias(\"std_volume_base_emissao\"),\n",
    "            F.stddev(\"qt_emissoes\").alias(\"std_qt_emissoes\"),\n",
    "            F.stddev(\"valor_cota_emissao\").alias(\"std_valor_cota_emissao\"),\n",
    "            F.stddev(\"taxa_distribuicao_emissao\").alias(\"std_taxa_distribuicao_emissao\"),\n",
    "            F.stddev(\"quantidade_cotas_totais\").alias(\"std_quantidade_cotas_totais\"),\n",
    "            F.stddev(\"percentual_oferta_institucional\").alias(\"std_percentual_oferta_institucional\"),\n",
    "            F.stddev(\"montante_minimo_emissao\").alias(\"std_montante_minimo_emissao\"),\n",
    "            F.mean(\"chamada_capital_ipca_flag\").alias(\"proporcao_chamada_capital_ipca\"),\n",
    "            F.mean(\"sharpe_ratio\").alias(\"media_sharpe_ratio\"),\n",
    "            F.sum(\"volume_base_emissao\").alias(\"volume_total_cluster\"),\n",
    "            F.mean(\"idade_anos\").alias(\"idade_media_anos\")\n",
    "        )\n",
    "\n",
    "        w_cluster = Window.partitionBy(\"cluster_id_full\")\n",
    "        df_hhi = self.df.withColumn(\n",
    "            \"prop_volume_cluster\",\n",
    "            F.col(\"volume_base_emissao\") / F.sum(\"volume_base_emissao\").over(w_cluster)\n",
    "        ).withColumn(\n",
    "            \"hhi_component\",\n",
    "            F.pow(F.col(\"prop_volume_cluster\"), 2)\n",
    "        )\n",
    "\n",
    "        hhi_df = df_hhi.groupBy(\"cluster_id_full\").agg(\n",
    "            F.sum(\"hhi_component\").alias(\"hhi_volume_base_emissao\")\n",
    "        )\n",
    "\n",
    "        self.final_df = agg_df.join(hhi_df, on=\"cluster_id_full\", how=\"left\").withColumn(\n",
    "            \"proporcao_participacao_mercado\",\n",
    "            F.col(\"volume_total_cluster\") / F.lit(volume_total_global)\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executa o pipeline de análise: carrega dados, prepara colunas e calcula agregados.\n",
    "        :return: DataFrame final com métricas agregadas por cluster\n",
    "        \"\"\"\n",
    "        self.load_data()\n",
    "        self.prepare_columns()\n",
    "        self.calculate_aggregates()\n",
    "        return self.final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "c2f20145-0ee7-4c82-b619-15fa23b7e262",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755183147861}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755183141850}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      },
      "2": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755183133643}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 2
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tipos_fundo = [\"fidc\", \"fii\", \"fip\"]\n",
    "\n",
    "# Itera sobre a lista e aplica a classe\n",
    "resultados = {}\n",
    "for tipo in tipos_fundo:\n",
    "    cm = ClusterMetrics(spark, tipo)\n",
    "    resultados[tipo] = cm.run()\n",
    "\n",
    "# Visualizando\n",
    "for tipo in tipos_fundo:\n",
    "    display(resultados[tipo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "0dcfdce1-1624-4fcd-9530-46b2fc305ecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for tipo in tipos_fundo:\n",
    "    # Recupera o DataFrame de clusters para o tipo de fundo\n",
    "    df_analise = resultados[tipo]\n",
    "\n",
    "    # Salva o DataFrame resultante no schema especificado, sobrescrevendo se já existir\n",
    "    tabela = f\"desafio_kinea.prospecto_fundos.analise_cluster_{tipo.lower()}\"\n",
    "    df_analise.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f8d4a8b-0d16-43b9-b4af-65b3833c74aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.2. Análise Kinea versus Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2ad44558-27bd-4fd0-b832-294de8e67a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Avaliando performance **conjunta** dos fundos KINEA em comparação aos fundos concorrentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "68da455a-2426-4d6e-9402-a9a1c54d45e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "class KineaClusterComparisonFull:\n",
    "    def __init__(self, df):\n",
    "        \"\"\"\n",
    "        Inicializa a classe com o DataFrame base\n",
    "        :param df: DataFrame contendo todos os fundos e clusters\n",
    "        \"\"\"\n",
    "        self.df = df\n",
    "        self.final_comp_df = None\n",
    "\n",
    "    def filter_kinea_clusters(self):\n",
    "        \"\"\"Mantém apenas clusters onde a Kinea está presente\"\"\"\n",
    "        clusters_kinea_ids = (\n",
    "            self.df.filter(F.upper(F.col(\"tipo_gestor\")) == \"KINEA\")\n",
    "                   .select(\"cluster_id\")\n",
    "                   .distinct()\n",
    "        )\n",
    "        self.df = self.df.join(clusters_kinea_ids, on=\"cluster_id\", how=\"inner\")\n",
    "\n",
    "    def prepare_columns(self):\n",
    "        \"\"\"Prepara colunas auxiliares\"\"\"\n",
    "        # Idade do fundo em anos (considera primeira emissão por CNPJ)\n",
    "        w_cnpj = Window.partitionBy(\"cnpj\")\n",
    "        self.df = self.df.withColumn(\n",
    "            \"idade_anos\",\n",
    "            F.datediff(F.current_date(), F.min(\"data_emissao\").over(w_cnpj)) / 365.25\n",
    "        )\n",
    "\n",
    "        # Flag binária chamada de capital IPCA\n",
    "        self.df = self.df.withColumn(\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            F.when(\n",
    "                F.upper(F.coalesce(F.col(\"chamada_capital_ipca\"), F.lit(\"NÃO\"))).like(\"%SIM%\"),\n",
    "                1\n",
    "            ).otherwise(0)\n",
    "        )\n",
    "\n",
    "        # Sharpe do fundo\n",
    "        self.df = self.df.withColumn(\n",
    "            \"sharpe_ratio_calc\",\n",
    "            F.when(F.col(\"volatilidade_historica\") != 0, F.col(\"retorno_acumulado\") / F.col(\"volatilidade_historica\")).otherwise(0)\n",
    "        )\n",
    "\n",
    "        # Volume total do cluster\n",
    "        w_cluster = Window.partitionBy(\"cluster_id\")\n",
    "        self.df = self.df.withColumn(\n",
    "            \"volume_total_cluster\",\n",
    "            F.sum(\"volume_base_emissao\").over(w_cluster)\n",
    "        )\n",
    "\n",
    "        # Market share do fundo\n",
    "        self.df = self.df.withColumn(\n",
    "            \"market_share_fundo\",\n",
    "            (F.col(\"volume_base_emissao\") / F.col(\"volume_total_cluster\")) * 100\n",
    "        )\n",
    "\n",
    "    def aggregate_metrics(self):\n",
    "        \"\"\"Agrega métricas por cluster e tipo_gestor\"\"\"\n",
    "        metrics = [\n",
    "            \"retorno_acumulado\",\n",
    "            \"volatilidade_historica\",\n",
    "            \"sharpe_ratio_calc\",\n",
    "            \"volume_base_emissao\",\n",
    "            \"qt_emissoes\",\n",
    "            \"valor_cota_emissao\",\n",
    "            \"taxa_distribuicao_emissao\",\n",
    "            \"quantidade_cotas_totais\",\n",
    "            \"percentual_oferta_institucional\",\n",
    "            \"montante_minimo_emissao\",\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            \"idade_anos\"\n",
    "        ]\n",
    "\n",
    "        agg_exprs = [F.mean(m).alias(m) for m in metrics]\n",
    "        agg_exprs += [\n",
    "            F.sum(\"volume_base_emissao\").alias(\"volume_total_gestor\"),\n",
    "            F.sum(\"market_share_fundo\").alias(\"market_share_gestor\"),\n",
    "            F.countDistinct(\"cnpj\").alias(\"qtd_fundos\")\n",
    "        ]\n",
    "\n",
    "        self.agg_metrics = self.df.groupBy(\"cluster_id\", \"tipo_gestor\").agg(*agg_exprs)\n",
    "\n",
    "    def pivot_and_compare(self):\n",
    "        \"\"\"Pivot Kinea vs Concorrentes e organiza lado a lado\"\"\"\n",
    "        # Pivot\n",
    "        pivot_df = self.agg_metrics.groupBy(\"cluster_id\").pivot(\"tipo_gestor\").agg(\n",
    "            *[F.first(c).alias(c) for c in self.agg_metrics.columns if c not in [\"cluster_id\", \"tipo_gestor\"]]\n",
    "        )\n",
    "\n",
    "        metrics = [\n",
    "            \"qtd_fundos\",\n",
    "            \"retorno_acumulado\",\n",
    "            \"volatilidade_historica\",\n",
    "            \"sharpe_ratio_calc\",\n",
    "            \"volume_base_emissao\",\n",
    "            \"qt_emissoes\",\n",
    "            \"valor_cota_emissao\",\n",
    "            \"taxa_distribuicao_emissao\",\n",
    "            \"quantidade_cotas_totais\",\n",
    "            \"percentual_oferta_institucional\",\n",
    "            \"montante_minimo_emissao\",\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            \"idade_anos\",\n",
    "            \"volume_total_gestor\",\n",
    "            \"market_share_gestor\"\n",
    "        ]\n",
    "\n",
    "        # Calcula diferenças Kinea vs Concorrente\n",
    "        for m in metrics:\n",
    "            pivot_df = pivot_df.withColumn(\n",
    "                f\"dif_{m}\",\n",
    "                F.coalesce(F.col(f\"KINEA_{m}\"), F.lit(0)) - F.coalesce(F.col(f\"CONCORRENTE_{m}\"), F.lit(0))\n",
    "            )\n",
    "\n",
    "        # Organiza colunas lado a lado\n",
    "        cols_lado_a_lado = [\"cluster_id\"]\n",
    "        for m in metrics:\n",
    "            cols_lado_a_lado += [f\"KINEA_{m}\", f\"CONCORRENTE_{m}\", f\"dif_{m}\"]\n",
    "\n",
    "        self.final_comp_df = pivot_df.filter(F.col(\"KINEA_qtd_fundos\").isNotNull()).select(*cols_lado_a_lado)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Executa todo o pipeline\"\"\"\n",
    "        self.filter_kinea_clusters()\n",
    "        self.prepare_columns()\n",
    "        self.aggregate_metrics()\n",
    "        self.pivot_and_compare()\n",
    "        return self.final_comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "06882126-8d7c-41a2-bbfa-4d4101d7763d",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755196649228}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      },
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755196649234}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      },
      "2": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755196649242}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 2
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "tipos_fundo = [\"fidc\", \"fii\", \"fip\"]\n",
    "\n",
    "# Itera sobre a lista e aplica a classe\n",
    "resultados = {}\n",
    "for tipo in tipos_fundo:\n",
    "    # Carrega o DataFrame do tipo de fundo\n",
    "    df_fundo = spark.table(f\"desafio_kinea.prospecto_fundos.resultados_cluster_{tipo}\")\n",
    "    \n",
    "    # Aplica a classe\n",
    "    kcc = KineaClusterComparisonFull(df_fundo)\n",
    "    resultados[tipo] = kcc.run()\n",
    "\n",
    "# Visualizando\n",
    "for tipo in tipos_fundo:\n",
    "    display(resultados[tipo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "4bc75c90-d18b-4d49-94ea-18d3564cef69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for tipo in tipos_fundo:\n",
    "    # Recupera o DataFrame de clusters para o tipo de fundo\n",
    "    df_analise = resultados[tipo]\n",
    "\n",
    "    # Salva o DataFrame resultante no schema especificado, substituindo se já existir\n",
    "    tabela = f\"desafio_kinea.prospecto_fundos.analise_cluster_kinea_conjunto_{tipo.lower()}\"\n",
    "    df_analise.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "872cc630-73fc-4465-aec1-f53da1e195a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Avaliando performance **individual** dos fundos KINEA em comparação aos fundos concorrentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cb49f8c-724b-419e-a8c8-4d16a48496dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "class KineaPerformance:\n",
    "    \"\"\"\n",
    "    Classe para análise de performance individual dos fundos KINEA em relação à média dos clusters.\n",
    "    Realiza carregamento de dados, preparação de colunas auxiliares, cálculo de métricas operacionais e financeiras,\n",
    "    comparação das métricas dos fundos KINEA com a média do cluster e cálculo do market share.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spark, tipo_fundo: str):\n",
    "        \"\"\"\n",
    "        Inicializa a classe com o objeto Spark e o tipo de fundo.\n",
    "        :param spark: sessão Spark ativa\n",
    "        :param tipo_fundo: tipo de fundo a ser analisado (ex: 'fidc', 'fii', 'fip')\n",
    "        \"\"\"\n",
    "        self.spark = spark\n",
    "        self.tipo_fundo = tipo_fundo.lower()\n",
    "        self.df = None\n",
    "        self.result_df = None\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Carrega os dados do cluster para o tipo de fundo especificado.\n",
    "        \"\"\"\n",
    "        path = f\"desafio_kinea.prospecto_fundos.resultados_cluster_{self.tipo_fundo}\"\n",
    "        self.df = self.spark.table(path)\n",
    "\n",
    "    def prepare_columns(self):\n",
    "        \"\"\"\n",
    "        Prepara colunas auxiliares para análise:\n",
    "        - Idade do fundo em anos (diferença entre hoje e primeira emissão por CNPJ)\n",
    "        - Flag binária para chamada de capital IPCA\n",
    "        - Sharpe do fundo (retorno/volatilidade), se as colunas existirem\n",
    "        \"\"\"\n",
    "        w_cnpj = Window.partitionBy(\"cnpj\")\n",
    "        self.df = self.df.withColumn(\n",
    "            \"idade_anos\",\n",
    "            F.datediff(F.current_date(), F.min(\"data_emissao\").over(w_cnpj)) / 365.25\n",
    "        )\n",
    "        self.df = self.df.withColumn(\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            F.when(\n",
    "                F.upper(F.coalesce(F.col(\"chamada_capital_ipca\"), F.lit(\"NÃO\"))).like(\"%SIM%\"),\n",
    "                1\n",
    "            ).otherwise(0)\n",
    "        )\n",
    "        if \"retorno_acumulado\" in self.df.columns and \"volatilidade_historica\" in self.df.columns:\n",
    "            self.df = self.df.withColumn(\n",
    "                \"sharpe_ratio_calc\",\n",
    "                F.when(F.col(\"volatilidade_historica\") != 0, F.col(\"retorno_acumulado\") / F.col(\"volatilidade_historica\")).otherwise(0)\n",
    "            )\n",
    "        else:\n",
    "            self.df = self.df.withColumn(\"sharpe_ratio_calc\", F.lit(0))\n",
    "\n",
    "    def calculate_performance(self):\n",
    "        \"\"\"\n",
    "        Calcula métricas operacionais e financeiras dos fundos KINEA e compara com a média do cluster.\n",
    "        - Calcula médias por cluster\n",
    "        - Junta médias do cluster com fundos KINEA\n",
    "        - Calcula diferenças KINEA vs média do cluster\n",
    "        - Calcula market share do fundo\n",
    "        \"\"\"\n",
    "        metrics = [\n",
    "            \"volume_base_emissao\",\n",
    "            \"qt_emissoes\",\n",
    "            \"valor_cota_emissao\",\n",
    "            \"taxa_distribuicao_emissao\",\n",
    "            \"quantidade_cotas_totais\",\n",
    "            \"percentual_oferta_institucional\",\n",
    "            \"montante_minimo_emissao\",\n",
    "            \"chamada_capital_ipca_flag\",\n",
    "            \"sharpe_ratio_calc\",\n",
    "            \"idade_anos\",\n",
    "        ]\n",
    "\n",
    "        financial_metrics = []\n",
    "        if \"retorno_acumulado\" in self.df.columns:\n",
    "            financial_metrics.append(\"retorno_acumulado\")\n",
    "        if \"volatilidade_historica\" in self.df.columns:\n",
    "            financial_metrics.append(\"volatilidade_historica\")\n",
    "\n",
    "        all_metrics = metrics + financial_metrics\n",
    "\n",
    "        cluster_metrics = self.df.groupBy(\"cluster_id_full\").agg(\n",
    "            *[F.mean(m).alias(f\"media_cluster_{m}\") for m in all_metrics],\n",
    "            F.sum(\"volume_base_emissao\").alias(\"volume_total_cluster\")\n",
    "        )\n",
    "\n",
    "        kinea_fundos = self.df.filter(F.upper(F.col(\"tipo_gestor\")) == \"KINEA\")\n",
    "\n",
    "        joined = kinea_fundos.join(cluster_metrics, on=\"cluster_id_full\", how=\"left\")\n",
    "\n",
    "        for m in all_metrics:\n",
    "            joined = joined.withColumn(\n",
    "                f\"{m}_diff\",\n",
    "                F.coalesce(F.col(m), F.lit(0)) - F.coalesce(F.col(f\"media_cluster_{m}\"), F.lit(0))\n",
    "            )\n",
    "\n",
    "        joined = joined.withColumn(\n",
    "            \"market_share_fundo\",\n",
    "            (F.col(\"volume_base_emissao\") / F.col(\"volume_total_cluster\") * 100)\n",
    "        ).withColumn(\n",
    "            \"dif_market_share\",\n",
    "            F.col(\"market_share_fundo\") - (F.col(\"media_cluster_volume_base_emissao\") / F.col(\"volume_total_cluster\") * 100)\n",
    "        )\n",
    "\n",
    "        select_cols = [\"cnpj\", \"nome_fundo\", \"cluster_id_full\"]\n",
    "        for m in all_metrics:\n",
    "            select_cols += [m, f\"media_cluster_{m}\", f\"{m}_diff\"]\n",
    "        select_cols += [\"volume_total_cluster\", \"market_share_fundo\", \"dif_market_share\"]\n",
    "\n",
    "        self.result_df = joined.select(*select_cols)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Executa o pipeline de análise: carrega dados, prepara colunas e calcula performance.\n",
    "        :return: DataFrame final com métricas individuais dos fundos KINEA e comparação com o cluster\n",
    "        \"\"\"\n",
    "        self.load_data()\n",
    "        self.prepare_columns()\n",
    "        self.calculate_performance()\n",
    "        return self.result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "25a34a37-0269-4143-b159-56c50718aecf",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1755191717370}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tipos_fundo = [\"fidc\", \"fii\", \"fip\"]\n",
    "resultados = {}\n",
    "\n",
    "for tipo in tipos_fundo:\n",
    "    # Cria instância da classe KineaPerformance para o tipo de fundo\n",
    "    kperf = KineaPerformance(spark, tipo)\n",
    "    # Executa o pipeline e salva o DataFrame no dicionário\n",
    "    resultados[tipo] = kperf.run()\n",
    "\n",
    "# Visualizar resultados\n",
    "for tipo in tipos_fundo:\n",
    "    print(f\"=== {tipo.upper()} ===\")\n",
    "    display(resultados[tipo])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1acf8ae4-b5da-4cc8-a0a9-a8e96be2d801",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for tipo in tipos_fundo:\n",
    "    # Recupera o DataFrame de clusters para o tipo de fundo\n",
    "    df_analise = resultados[tipo]\n",
    "\n",
    "    # Salva o DataFrame resultante no schema especificado, sobrescrevendo se já existir\n",
    "    tabela = f\"desafio_kinea.prospecto_fundos.analise_cluster_kinea_individual_{tipo.lower()}\"\n",
    "    df_analise.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(tabela)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc817bd4-8bd6-4c30-94bd-4e77ccf58511",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.2.1. Análises Gráficas KINEA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "d29cb9fc-a5dc-4218-a915-a9c4a77f748e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Carregar os dados\n",
    "df = spark.table(\"desafio_kinea.prospecto_fundos.resultados_cluster_fidc\").toPandas()\n",
    "\n",
    "# Filtrar dados da Kinea\n",
    "kinea = df[df['tipo_gestor'].str.upper() == 'KINEA']\n",
    "\n",
    "# Variáveis para análise\n",
    "variaveis = [\n",
    "    \"valor_cota_emissao\",\n",
    "    \"quantidade_cotas_totais\",\n",
    "    \"montante_minimo_emissao\",\n",
    "    \"volume_base_emissao\", \n",
    "    \"taxa_distribuicao_emissao\"\n",
    "]\n",
    "\n",
    "# Configurações de plot\n",
    "plt.style.use('seaborn')\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "for var in variaveis:\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # --- BOXPLOT ---\n",
    "    plt.subplot(1, 2, 1)\n",
    "    \n",
    "    # Boxplot com violino\n",
    "    sns.violinplot(x=var, data=df, color='lightgray', inner=None)\n",
    "    sns.boxplot(x=var, data=df, width=0.1, color='white', \n",
    "                showcaps=True, fliersize=3)\n",
    "    \n",
    "    # Destacar Kinea\n",
    "    for val in kinea[var]:\n",
    "        plt.axvline(val, color='red', linestyle='-', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    # Estatísticas descritivas\n",
    "    mean_val = df[var].mean()\n",
    "    median_val = df[var].median()\n",
    "    plt.axvline(mean_val, color='green', linestyle='--', linewidth=2, label=f'Média: {mean_val:.2f}')\n",
    "    plt.axvline(median_val, color='blue', linestyle=':', linewidth=2, label=f'Mediana: {median_val:.2f}')\n",
    "    \n",
    "    plt.title(f'Distribuição de {var}\\nPosição da Kinea', fontsize=12, pad=20)\n",
    "    plt.xlabel(var)\n",
    "    plt.legend()\n",
    "    \n",
    "    # --- HISTOGRAMA ---\n",
    "    plt.subplot(1, 2, 2)\n",
    "    \n",
    "    # Histograma com KDE\n",
    "    sns.histplot(df[var], bins=30, kde=True, color='skyblue', alpha=0.7)\n",
    "    \n",
    "    # Linhas para Kinea\n",
    "    for val in kinea[var]:\n",
    "        plt.axvline(val, color='red', linestyle='-', linewidth=2, alpha=0.7, label='Kinea')\n",
    "    \n",
    "    # Linhas para estatísticas\n",
    "    plt.axvline(mean_val, color='green', linestyle='--', linewidth=2, label='Média')\n",
    "    plt.axvline(median_val, color='blue', linestyle=':', linewidth=2, label='Mediana')\n",
    "    \n",
    "    # Ajustar escala se necessário\n",
    "    if df[var].skew() > 1:\n",
    "        plt.xscale('log')\n",
    "        plt.xlabel(f'{var} (escala log)')\n",
    "    \n",
    "    plt.title(f'Histograma de {var}', fontsize=12, pad=20)\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3cb6cefb-47f2-4342-b1d0-2395cd120f0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 1.3. Potenciais Novas Emissões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "990c62c4-f40e-4520-94c5-dfde52b43586",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tipos_fundo = [\"fidc\", \"fii\", \"fip\"]\n",
    "\n",
    "for tipo in tipos_fundo:\n",
    "    df = spark.table(f\"desafio_kinea.prospecto_fundos.resultados_cluster_{tipo}\")\n",
    "    fundos_potenciais = df.filter(F.col(\"potencial_nova_emissao\") == True)\n",
    "    display(fundos_potenciais)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "04_analises",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
